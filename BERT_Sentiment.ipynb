{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_Sentiment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "13LFkE8CBwa6YE1qFTW6WzGVCCQQHm_KX",
      "authorship_tag": "ABX9TyN2TradlV5fh3/IJly0I2j4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4507489fdcdf4f0497b5b1cbd9773244": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_32ccde69206048d0992ae50311723bbf",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6189d921f5b340b6b2c40c36d4a8a220",
              "IPY_MODEL_f1beff60c31849068a88f03412806ba4"
            ]
          }
        },
        "32ccde69206048d0992ae50311723bbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6189d921f5b340b6b2c40c36d4a8a220": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f2cd4ed53188420d95ae2a2bd496d9fd",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 196,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 196,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9d19ff055deb46fa82c6e11d7d3367c6"
          }
        },
        "f1beff60c31849068a88f03412806ba4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6b2294d5a84342c595802021a0539904",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 196/196 [08:30&lt;00:00,  2.60s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fa55fd7e8ba4485085c5c3721d73fce9"
          }
        },
        "f2cd4ed53188420d95ae2a2bd496d9fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9d19ff055deb46fa82c6e11d7d3367c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6b2294d5a84342c595802021a0539904": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fa55fd7e8ba4485085c5c3721d73fce9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VedantDere0104/BERT_Sentiment/blob/main/BERT_Sentiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nntepYnywlPL"
      },
      "source": [
        "####"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_eov9H9Vw19L",
        "outputId": "8fece2d9-f020-4ad9-97ce-75eb1f6fa5e2"
      },
      "source": [
        "! pip install transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (4.3.2)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.10.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83LS8d4AwwDb"
      },
      "source": [
        "import torch\r\n",
        "\r\n",
        "import random\r\n",
        "import numpy as np\r\n",
        "SEED = 1234\r\n",
        "\r\n",
        "random.seed(SEED)\r\n",
        "np.random.seed(SEED)\r\n",
        "torch.manual_seed(SEED)\r\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8hlXA1twybS"
      },
      "source": [
        "\r\n",
        "from transformers import BertTokenizer\r\n",
        "\r\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66YmpaZIw0Zv",
        "outputId": "f29f6ab6-38d7-4eb8-cf67-60ace2e2065a"
      },
      "source": [
        "init_token_idx = tokenizer.cls_token_id\r\n",
        "eos_token_idx = tokenizer.sep_token_id\r\n",
        "pad_token_idx = tokenizer.pad_token_id\r\n",
        "unk_token_idx = tokenizer.unk_token_id\r\n",
        "len(tokenizer.vocab)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30522"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uq5NK8bzw8tv",
        "outputId": "2d0f3309-4eb6-4165-d331-c2eff7a4431c"
      },
      "source": [
        "max_input_length = tokenizer.max_model_input_sizes['bert-base-uncased']\r\n",
        "max_input_length"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "512"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4jKkct_xEWA"
      },
      "source": [
        "def tokenize_and_cut(sentence):\r\n",
        "    tokens = tokenizer.tokenize(sentence) \r\n",
        "    tokens = tokens[:max_input_length-2]\r\n",
        "    return tokens"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PS13BJcsxGGi"
      },
      "source": [
        "\r\n",
        "from torchtext import data\r\n",
        "\r\n",
        "TEXT = data.Field(batch_first = True,\r\n",
        "                  use_vocab = False,\r\n",
        "                  tokenize = tokenize_and_cut,\r\n",
        "                  preprocessing = tokenizer.convert_tokens_to_ids,\r\n",
        "                  init_token = init_token_idx,\r\n",
        "                  eos_token = eos_token_idx,\r\n",
        "                  pad_token = pad_token_idx,\r\n",
        "                  unk_token = unk_token_idx)\r\n",
        "\r\n",
        "LABEL = data.LabelField(dtype = torch.float)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNE5RTPMxNMu"
      },
      "source": [
        "from torchtext import datasets\r\n",
        "\r\n",
        "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)\r\n",
        "\r\n",
        "train_data, valid_data = train_data.split(random_state = random.seed(SEED))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEs83l0pxY-J",
        "outputId": "38bf8889-89bc-43bf-941c-1bc13669615c"
      },
      "source": [
        "\r\n",
        "print(f\"Number of training examples: {len(train_data)}\")\r\n",
        "print(f\"Number of validation examples: {len(valid_data)}\")\r\n",
        "print(f\"Number of testing examples: {len(test_data)}\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 17500\n",
            "Number of validation examples: 7500\n",
            "Number of testing examples: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_TLahF0ypLs",
        "outputId": "6b06bc3c-0d3e-4413-b4ca-6323922d848d"
      },
      "source": [
        "print(vars(train_data.examples[6]))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'text': [2023, 3185, 2001, 7917, 1999, 2563, 1029, 2339, 1029, 3419, 7842, 6371, 2072, 1010, 2577, 18290, 1010, 26800, 23157, 2080, 1010, 12776, 3695, 11865, 15472, 2072, 1998, 2500, 2018, 2589, 2521, 4788, 2077, 1998, 2031, 2506, 2000, 2061, 2144, 1012, 1012, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 2023, 3185, 2038, 2035, 1996, 3937, 3787, 1997, 1037, 11519, 17549, 2030, 2220, 3770, 1005, 1055, 5469, 2143, 1012, 2204, 2559, 3057, 1006, 2040, 2064, 1005, 1056, 2552, 2000, 3828, 2037, 3268, 1010, 2011, 1996, 2126, 1007, 1010, 1037, 6659, 7407, 4040, 2007, 1037, 22047, 19909, 2091, 27757, 1010, 1037, 8040, 26688, 1010, 1037, 4689, 2567, 13071, 2105, 1996, 2155, 3776, 1010, 1998, 2941, 1037, 3492, 4365, 2204, 9792, 2012, 1996, 2203, 1012, 2021, 7917, 1029, 5667, 1012, 2043, 1996, 2394, 3323, 7917, 2023, 3185, 1010, 1996, 16773, 2763, 4191, 2037, 7268, 4632, 2229, 2125, 2012, 2129, 11043, 1998, 10975, 21041, 4095, 1996, 28101, 2015, 2428, 2020, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 2045, 2001, 2672, 2048, 2781, 1997, 2561, 3898, 2051, 7422, 2000, 1996, 4808, 1998, 13638, 1006, 2029, 2001, 6551, 2104, 5280, 2063, 1007, 1012, 2045, 2001, 16371, 25469, 2021, 2053, 3348, 2348, 2035, 22016, 2000, 3348, 2020, 2081, 1010, 5525, 1012, 2021, 7078, 2498, 11007, 1997, 2108, 7917, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 1045, 2052, 2066, 2000, 2156, 2054, 2071, 2031, 2042, 2589, 2065, 1996, 16587, 2018, 1037, 11519, 5166, 2000, 2147, 2007, 1012, 2004, 2009, 4832, 1010, 1996, 2143, 2003, 14036, 1010, 2021, 1996, 3768, 1997, 3861, 1998, 2614, 3737, 2202, 2185, 2013, 1996, 2203, 2765, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 7917, 1012, 1012, 1012, 2054, 1037, 8257, 1012, 1012, 1012], 'label': 'neg'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8EUVasyyrbD",
        "outputId": "a0926a62-beed-4bb1-e65d-b3f12e5d4c03"
      },
      "source": [
        "\r\n",
        "tokens = tokenizer.convert_ids_to_tokens(vars(train_data.examples[6])['text'])\r\n",
        "\r\n",
        "print(tokens)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['this', 'movie', 'was', 'banned', 'in', 'england', '?', 'why', '?', 'tom', 'sa', '##vin', '##i', ',', 'george', 'romero', ',', 'dario', 'argent', '##o', ',', 'luc', '##io', 'fu', '##lc', '##i', 'and', 'others', 'had', 'done', 'far', 'worse', 'before', 'and', 'have', 'continued', 'to', 'so', 'since', '.', '.', '.', '<', 'br', '/', '>', '<', 'br', '/', '>', 'this', 'movie', 'has', 'all', 'the', 'basic', 'elements', 'of', 'a', 'decent', '70s', 'or', 'early', '80', \"'\", 's', 'horror', 'film', '.', 'good', 'looking', 'girls', '(', 'who', 'can', \"'\", 't', 'act', 'to', 'save', 'their', 'lives', ',', 'by', 'the', 'way', ')', ',', 'a', 'terrible', 'lightning', 'storm', 'with', 'a', 'torre', '##ntial', 'down', '##pour', ',', 'a', 'sc', '##ythe', ',', 'a', 'crazy', 'brother', 'wandering', 'around', 'the', 'family', 'estate', ',', 'and', 'actually', 'a', 'pretty', 'damn', 'good', 'twist', 'at', 'the', 'end', '.', 'but', 'banned', '?', 'seriously', '.', 'when', 'the', 'english', 'parliament', 'banned', 'this', 'movie', ',', 'the', 'italians', 'probably', 'laughed', 'their', 'collective', 'ass', '##es', 'off', 'at', 'how', 'backwards', 'and', 'pr', '##udi', '##sh', 'the', 'brit', '##s', 'really', 'were', '.', '<', 'br', '/', '>', '<', 'br', '/', '>', 'there', 'was', 'maybe', 'two', 'minutes', 'of', 'total', 'screen', 'time', 'devoted', 'to', 'the', 'violence', 'and', 'gore', '(', 'which', 'was', 'greatly', 'under', '##don', '##e', ')', '.', 'there', 'was', 'nu', '##dity', 'but', 'no', 'sex', 'although', 'all', '##usions', 'to', 'sex', 'were', 'made', ',', 'obviously', '.', 'but', 'absolutely', 'nothing', 'worthy', 'of', 'being', 'banned', '.', '<', 'br', '/', '>', '<', 'br', '/', '>', 'i', 'would', 'like', 'to', 'see', 'what', 'could', 'have', 'been', 'done', 'if', 'the', 'filmmakers', 'had', 'a', 'decent', 'budget', 'to', 'work', 'with', '.', 'as', 'it', 'stands', ',', 'the', 'film', 'is', 'entertaining', ',', 'but', 'the', 'lack', 'of', 'picture', 'and', 'sound', 'quality', 'take', 'away', 'from', 'the', 'end', 'result', '.', '<', 'br', '/', '>', '<', 'br', '/', '>', 'banned', '.', '.', '.', 'what', 'a', 'joke', '.', '.', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zeL-_8By0ta"
      },
      "source": [
        "LABEL.build_vocab(train_data)\r\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJrvtKTYy2el",
        "outputId": "1fc1e264-6ffd-47cf-f8d6-26f642b652b6"
      },
      "source": [
        "\r\n",
        "print(LABEL.vocab.stoi)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "defaultdict(<function _default_unk_index at 0x7fae08d20d90>, {'neg': 0, 'pos': 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9EAKek3y9AC"
      },
      "source": [
        "\r\n",
        "BATCH_SIZE = 128\r\n",
        "\r\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\r\n",
        "\r\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\r\n",
        "    (train_data, valid_data, test_data), \r\n",
        "    batch_size = BATCH_SIZE, \r\n",
        "    device = device)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvhS9cU2zA5J"
      },
      "source": [
        "from transformers import BertTokenizer, BertModel\r\n",
        "\r\n",
        "bert = BertModel.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0K1C3YvHzC-t"
      },
      "source": [
        "\r\n",
        "import torch.nn as nn\r\n",
        "\r\n",
        "class BERTGRUSentiment(nn.Module):\r\n",
        "    def __init__(self,\r\n",
        "                 bert,\r\n",
        "                 hidden_dim,\r\n",
        "                 output_dim,\r\n",
        "                 n_layers,\r\n",
        "                 bidirectional,\r\n",
        "                 dropout):\r\n",
        "        \r\n",
        "        super().__init__()\r\n",
        "        \r\n",
        "        self.bert = bert\r\n",
        "        \r\n",
        "        embedding_dim = bert.config.to_dict()['hidden_size']\r\n",
        "        \r\n",
        "        self.rnn = nn.GRU(embedding_dim,\r\n",
        "                          hidden_dim,\r\n",
        "                          num_layers = n_layers,\r\n",
        "                          bidirectional = bidirectional,\r\n",
        "                          batch_first = True,\r\n",
        "                          dropout = 0 if n_layers < 2 else dropout)\r\n",
        "        \r\n",
        "        self.out = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\r\n",
        "        \r\n",
        "        self.dropout = nn.Dropout(dropout)\r\n",
        "        \r\n",
        "    def forward(self, text):\r\n",
        "        \r\n",
        "        #text = [batch size, sent len]\r\n",
        "                \r\n",
        "        with torch.no_grad():\r\n",
        "            embedded = self.bert(text)[0]\r\n",
        "                \r\n",
        "        #embedded = [batch size, sent len, emb dim]\r\n",
        "        \r\n",
        "        _, hidden = self.rnn(embedded)\r\n",
        "        \r\n",
        "        #hidden = [n layers * n directions, batch size, emb dim]\r\n",
        "        \r\n",
        "        if self.rnn.bidirectional:\r\n",
        "            hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\r\n",
        "        else:\r\n",
        "            hidden = self.dropout(hidden[-1,:,:])\r\n",
        "                \r\n",
        "        #hidden = [batch size, hid dim]\r\n",
        "        \r\n",
        "        output = self.out(hidden)\r\n",
        "        \r\n",
        "        #output = [batch size, out dim]\r\n",
        "        \r\n",
        "        return output"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wRpvdSSzF-9"
      },
      "source": [
        "HIDDEN_DIM = 256\r\n",
        "OUTPUT_DIM = 1\r\n",
        "N_LAYERS = 2\r\n",
        "BIDIRECTIONAL = True\r\n",
        "DROPOUT = 0.25\r\n",
        "\r\n",
        "model = BERTGRUSentiment(bert,\r\n",
        "                         HIDDEN_DIM,\r\n",
        "                         OUTPUT_DIM,\r\n",
        "                         N_LAYERS,\r\n",
        "                         BIDIRECTIONAL,\r\n",
        "                         DROPOUT)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caJeHtEKzIFy",
        "outputId": "6c0bc276-0a6b-46f9-896b-672e49057c99"
      },
      "source": [
        "def count_parameters(model):\r\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\r\n",
        "\r\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 112,241,409 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JENObAlzLBv"
      },
      "source": [
        "for name, param in model.named_parameters():                \r\n",
        "    if name.startswith('bert'):\r\n",
        "        param.requires_grad = False"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1ZuPGIxzM60",
        "outputId": "7b9aad3d-2cc4-4157-a625-3c34bc5f9d17"
      },
      "source": [
        "\r\n",
        "for name, param in model.named_parameters():                \r\n",
        "    if param.requires_grad:\r\n",
        "        print(name)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rnn.weight_ih_l0\n",
            "rnn.weight_hh_l0\n",
            "rnn.bias_ih_l0\n",
            "rnn.bias_hh_l0\n",
            "rnn.weight_ih_l0_reverse\n",
            "rnn.weight_hh_l0_reverse\n",
            "rnn.bias_ih_l0_reverse\n",
            "rnn.bias_hh_l0_reverse\n",
            "rnn.weight_ih_l1\n",
            "rnn.weight_hh_l1\n",
            "rnn.bias_ih_l1\n",
            "rnn.bias_hh_l1\n",
            "rnn.weight_ih_l1_reverse\n",
            "rnn.weight_hh_l1_reverse\n",
            "rnn.bias_ih_l1_reverse\n",
            "rnn.bias_hh_l1_reverse\n",
            "out.weight\n",
            "out.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPoBABNWzOjh"
      },
      "source": [
        "import torch.optim as optim\r\n",
        "\r\n",
        "optimizer = optim.Adam(model.parameters())"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtSy-gukzQUO"
      },
      "source": [
        "\r\n",
        "criterion = nn.BCEWithLogitsLoss()"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmcSGAdAzRs_"
      },
      "source": [
        "model = model.to(device)\r\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xm32snNEzTW6"
      },
      "source": [
        "\r\n",
        "def binary_accuracy(preds, y):\r\n",
        "    \"\"\"\r\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    #round predictions to the closest integer\r\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\r\n",
        "    correct = (rounded_preds == y).float() #convert into float for division \r\n",
        "    acc = correct.sum() / len(correct)\r\n",
        "    return acc"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXBDayQFzVB5"
      },
      "source": [
        "\r\n",
        "def train(model, iterator, optimizer, criterion):\r\n",
        "    \r\n",
        "    epoch_loss = 0\r\n",
        "    epoch_acc = 0\r\n",
        "    \r\n",
        "    model.train()\r\n",
        "    \r\n",
        "    for batch in iterator:\r\n",
        "        \r\n",
        "        optimizer.zero_grad()\r\n",
        "        \r\n",
        "        predictions = model(batch.text).squeeze(1)\r\n",
        "        \r\n",
        "        loss = criterion(predictions, batch.label)\r\n",
        "        \r\n",
        "        acc = binary_accuracy(predictions, batch.label)\r\n",
        "        \r\n",
        "        loss.backward()\r\n",
        "        \r\n",
        "        optimizer.step()\r\n",
        "        \r\n",
        "        epoch_loss += loss.item()\r\n",
        "        epoch_acc += acc.item()\r\n",
        "        \r\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TK_WIMSHzWxs"
      },
      "source": [
        "from tqdm.auto import tqdm\r\n",
        "def evaluate(model, iterator, criterion):\r\n",
        "    \r\n",
        "    epoch_loss = 0\r\n",
        "    epoch_acc = 0\r\n",
        "    \r\n",
        "    model.eval()\r\n",
        "    \r\n",
        "    with torch.no_grad():\r\n",
        "    \r\n",
        "        for batch in tqdm(iterator):\r\n",
        "\r\n",
        "            predictions = model(batch.text).squeeze(1)\r\n",
        "            \r\n",
        "            loss = criterion(predictions, batch.label)\r\n",
        "            \r\n",
        "            acc = binary_accuracy(predictions, batch.label)\r\n",
        "\r\n",
        "            epoch_loss += loss.item()\r\n",
        "            epoch_acc += acc.item()\r\n",
        "        \r\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LW5dtAZuzYqH"
      },
      "source": [
        "\r\n",
        "import time\r\n",
        "\r\n",
        "def epoch_time(start_time, end_time):\r\n",
        "    elapsed_time = end_time - start_time\r\n",
        "    elapsed_mins = int(elapsed_time / 60)\r\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\r\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2GdhFGrGzac9",
        "outputId": "d31d3a95-be4c-4195-e755-4c601a8c4a79"
      },
      "source": [
        "N_EPOCHS = 5\r\n",
        "\r\n",
        "best_valid_loss = float('inf')\r\n",
        "\r\n",
        "for epoch in range(N_EPOCHS):\r\n",
        "    \r\n",
        "    start_time = time.time()\r\n",
        "    \r\n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\r\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\r\n",
        "        \r\n",
        "    end_time = time.time()\r\n",
        "        \r\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\r\n",
        "        \r\n",
        "    if valid_loss < best_valid_loss:\r\n",
        "        best_valid_loss = valid_loss\r\n",
        "        torch.save(model.state_dict(), '/content/drive/MyDrive/Relatas_Assignment/tut6-model.pt')\r\n",
        "    \r\n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\r\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\r\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 15m 45s\n",
            "\tTrain Loss: 0.319 | Train Acc: 86.85%\n",
            "\t Val. Loss: 0.265 |  Val. Acc: 89.30%\n",
            "Epoch: 02 | Epoch Time: 15m 47s\n",
            "\tTrain Loss: 0.246 | Train Acc: 90.18%\n",
            "\t Val. Loss: 0.234 |  Val. Acc: 90.76%\n",
            "Epoch: 03 | Epoch Time: 15m 46s\n",
            "\tTrain Loss: 0.214 | Train Acc: 91.70%\n",
            "\t Val. Loss: 0.227 |  Val. Acc: 90.91%\n",
            "Epoch: 04 | Epoch Time: 15m 46s\n",
            "\tTrain Loss: 0.189 | Train Acc: 92.73%\n",
            "\t Val. Loss: 0.227 |  Val. Acc: 91.18%\n",
            "Epoch: 05 | Epoch Time: 15m 44s\n",
            "\tTrain Loss: 0.168 | Train Acc: 93.51%\n",
            "\t Val. Loss: 0.259 |  Val. Acc: 90.61%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "4507489fdcdf4f0497b5b1cbd9773244",
            "32ccde69206048d0992ae50311723bbf",
            "6189d921f5b340b6b2c40c36d4a8a220",
            "f1beff60c31849068a88f03412806ba4",
            "f2cd4ed53188420d95ae2a2bd496d9fd",
            "9d19ff055deb46fa82c6e11d7d3367c6",
            "6b2294d5a84342c595802021a0539904",
            "fa55fd7e8ba4485085c5c3721d73fce9"
          ]
        },
        "id": "M0l0JzigzdH9",
        "outputId": "e8ff991d-2982-428a-89e2-41962228b111"
      },
      "source": [
        "model.load_state_dict(torch.load('/content/drive/MyDrive/Relatas_Assignment/tut6-model.pt'))\r\n",
        "\r\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion)\r\n",
        "\r\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4507489fdcdf4f0497b5b1cbd9773244",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=196.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test Loss: 0.204 | Test Acc: 91.73%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nalb0ebNMAQg"
      },
      "source": [
        "def predict_sentiment(model, tokenizer, sentence):\r\n",
        "    model.eval()\r\n",
        "    tokens = tokenizer.tokenize(sentence)\r\n",
        "    tokens = tokens[:max_input_length-2]\r\n",
        "    indexed = [init_token_idx] + tokenizer.convert_tokens_to_ids(tokens) + [eos_token_idx]\r\n",
        "    tensor = torch.LongTensor(indexed).to(device)\r\n",
        "    tensor = tensor.unsqueeze(0)\r\n",
        "    prediction = torch.sigmoid(model(tensor))\r\n",
        "    return prediction.item()"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5p_YlOlOmDc",
        "outputId": "e6f8c518-705d-41fb-daf6-8165abca2e42"
      },
      "source": [
        "predict_sentiment(model, tokenizer, \"This film is terrible\")"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.028803542256355286"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4nTLh7QOndz",
        "outputId": "cba23b9d-1174-4c48-e37b-ca62f0ce828d"
      },
      "source": [
        "predict_sentiment(model, tokenizer, \"This film is great\")"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9502979516983032"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1j6DZ-2Oo48",
        "outputId": "79a77a31-219d-4b5e-9ef6-bf9a32b5bcb8"
      },
      "source": [
        "predict_sentiment(model, tokenizer, \"We are greatly appreciative of all of ZS's hard work and cooperation with us on this project.\")"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.580721914768219"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2dr7TwEQg7S"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}